{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Classifier"
      ],
      "metadata": {
        "id": "avHZGTaaMm3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "rgG99PlPMqhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "1ZyTmfC_MsD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the data"
      ],
      "metadata": {
        "id": "SYL8pOV3Mtr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the complete dataset in iris\n",
        "dataset = pd.read_csv('/content/iris_data.csv')\n",
        "iris = datasets.load_iris()\n"
      ],
      "metadata": {
        "id": "fB4a3EamMxBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Getting independent and dependent variables"
      ],
      "metadata": {
        "id": "HnGLRASENwVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we only take the first two features(sepal_length, sepal width)\n",
        "X = iris.data[:, :2]\n",
        "\n",
        "# Target variable \"Species\"\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "8GN3mPOlNzDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualising classification regions\n",
        "The purpose of meshgrid is to create a rectangular grid out of an array of x values and an array of y values."
      ],
      "metadata": {
        "id": "xTzaL_pkN-j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create a mesh-grid to show the classification regions\n",
        "\n",
        "# defining limit for the x axis\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "\n",
        "# defining limit for y axis\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "# 0.01 step size with respect to x limit\n",
        "h = (x_max / x_min)/100\n",
        "\n",
        "# defining the meshgrid with above parameters\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))"
      ],
      "metadata": {
        "id": "0KET_wNMOB_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the Regions\n",
        "1. Instantiating SVC (Default)"
      ],
      "metadata": {
        "id": "ysOIN7I_OG2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X, y)"
      ],
      "metadata": {
        "id": "rdvf3byiOI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the default parameters of the SVM classifier as displayed above, the default kernel used is 'rbf'. Let's visualise what it looks like."
      ],
      "metadata": {
        "id": "I22n_GWKOMA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#plotting"
      ],
      "metadata": {
        "id": "IuXvdt3SON_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5), dpi = 80)\n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.7)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('Default SVM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q9v1WoQPOQLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Linear SVM"
      ],
      "metadata": {
        "id": "MwiHTIZuOUoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel = 'linear')\n",
        "svc.fit(X, y)"
      ],
      "metadata": {
        "id": "M8GdTSeqOSmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting"
      ],
      "metadata": {
        "id": "5qMAaw7BOaRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5), dpi = 80)\n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.7)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('Default SVM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f9FbDS2MOcP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that Linear SVM creates the classification curve which is linear or a straight line. therfore misclassification isunavoidable and prominent."
      ],
      "metadata": {
        "id": "p_q8eJvLOe74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. SVM with polynomial kernel"
      ],
      "metadata": {
        "id": "iyH5Yin2OhAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel = 'poly')\n",
        "svc.fit(X, y)"
      ],
      "metadata": {
        "id": "smQxIWvZOjAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting"
      ],
      "metadata": {
        "id": "W8L1v4oYOliW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5), dpi = 80)\n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('Default polynomial SVM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MQRs6p6LOngo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the polynomial kernel is able capture the nonlinear relation, the most prominent paramter with this kernel is the degree of polynomial features. So let's have a look at the different degrees."
      ],
      "metadata": {
        "id": "W5VvPmWbOqvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Polynimial SVM with different degrees"
      ],
      "metadata": {
        "id": "WERkb8D-OtSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,5))\n",
        "\n",
        "\n",
        "for i in range(2,6):\n",
        "  svc = SVC(kernel = 'poly', degree = i)\n",
        "  svc.fit(X, y)\n",
        "\n",
        "  plt.subplot(1,4,i-1)\n",
        "  Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "\n",
        "  plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "  plt.xlabel('Sepal length')\n",
        "  plt.ylabel('Sepal width')\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.title('Polynomial kernel: degree = '+ str(i))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CKdoRF8fOv_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that as the degree of the polynomial increases, the separating line starts to exhibit a complex nature. You can also notice that it took more than usual time to run the model with degree 5 for a dataset so small. Which validates our claim that polynomial kernel requires high computational power."
      ],
      "metadata": {
        "id": "8Yhm6lCyOzbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM with 'rbf' / gaussian kernel"
      ],
      "metadata": {
        "id": "5CUeXA56O1uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel = 'rbf')\n",
        "svc.fit(X, y)"
      ],
      "metadata": {
        "id": "SA4hFVGOO55o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting"
      ],
      "metadata": {
        "id": "xI8Rb7r3O8Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5), dpi = 80)\n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('rbf Kernel: default parameters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_D-ryAsO-Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameters that governs the performance of the 'rbf' are the parameters \"C\" which is the regularisation parameter and \"GAMMA\" which is the distance of margin of the classifier.\n",
        "\n",
        "Let' see see how these parameters affect the SVC model."
      ],
      "metadata": {
        "id": "xdVqVNfPPFTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change with respect to gamma ( C = constant)"
      ],
      "metadata": {
        "id": "ShJjkivYPI06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "g = [0.1,1,10,15,100,1000]\n",
        "for i in range(len(g)):\n",
        "  svc = SVC(kernel = 'rbf', gamma = g[i])\n",
        "  svc.fit(X, y)\n",
        "\n",
        "  plt.subplot(2,3,i+1)\n",
        "  Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "\n",
        "  plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "  plt.xlabel('Sepal length')\n",
        "  plt.ylabel('Sepal width')\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.title('rbf kernel: gamma = '+ str(g[i]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AXuCsKsMO-Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that taking a very small value of Gamma in SVC is similar to using the linear SVC, but as we increase the Value of the gamma , the classification process improves but starts to over fit if we take a very hight value of the GAMMA.\n",
        "\n",
        "The important thing to note is the nature of overfitting when Gamma is 1000, each and everypoint is correctly classified and is almost perfectly isolated in circular classification curves."
      ],
      "metadata": {
        "id": "XfI-gpsJPNyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change with respect to C ( gamma = constant)"
      ],
      "metadata": {
        "id": "oiZvoQjvPPq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "c =[1,10,100,1000,10000,100000]\n",
        "for i in range(len(c)):\n",
        "  svc = SVC(kernel = 'rbf', C = c[i], gamma=0.5)\n",
        "  svc.fit(X, y)\n",
        "\n",
        "  plt.subplot(2,3,i+1)\n",
        "  Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.7)\n",
        "\n",
        "\n",
        "  plt.scatter(X[:, 0], X[:, 1] , c = y, cmap=plt.cm.Paired)\n",
        "  plt.xlabel('Sepal length')\n",
        "  plt.ylabel('Sepal width')\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.title('rbf kernel: C = '+ str(c[i]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qTiXphJjPR2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}